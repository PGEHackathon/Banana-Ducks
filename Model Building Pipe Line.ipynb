{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building Pipe Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be establishing the model pipe line that we want to use in order to create our final model to evaluate the problem for the 2024 Hackathon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following will be the path to the data that we want to use. The following are the assumptions about the data before submitting it to the model building:\n",
    "\n",
    "1. Data has been cleaned and contains no NaNs\n",
    "2. Data has been normalized per feature\n",
    "3. Categorical data has been correctly dealt with (OHE)\n",
    "4. Target variable is labeled as: \"AVG PUMP DIFFERENCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put in the path to the data here\n",
    "path_to_data = \"Final_dataset.csv\"\n",
    "\n",
    "raw_df = pd.read_csv(path_to_data)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to split the training from the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = raw_df[raw_df[\"Avg Pump Difference\"].isna()].reset_index(drop = True)\n",
    "train_df = raw_df[~raw_df[\"Avg Pump Difference\"].isna()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, SGDRegressor\n",
    "\n",
    "# Kernel Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "\n",
    "# Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = train_df.columns.tolist()\n",
    "\n",
    "y = \"Avg Pump Difference\"\n",
    "\n",
    "all_cols.remove(y)\n",
    "x = all_cols\n",
    "\n",
    "X_train = train_df[x]\n",
    "Y_train = train_df[[y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, X, Y, num_folds):\n",
    "    kf = KFold(n_splits=num_folds, shuffle = True)\n",
    "    \n",
    "    total = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        train_X = X[train_index,:]\n",
    "        train_Y = Y.iloc[train_index,:]\n",
    "        \n",
    "        test_X = X[test_index,:]\n",
    "        test_Y = Y.iloc[test_index,:]\n",
    "        \n",
    "        model.fit(train_X, train_Y)\n",
    "        \n",
    "        pred_Y = model.predict(test_X)\n",
    "        \n",
    "        cur_accuracy = mean_squared_error(test_Y, pred_Y)\n",
    "        total.append(cur_accuracy)\n",
    "        \n",
    "    return sum(total)/len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Linear\", LinearRegression()),\n",
    "    (\"Ridge - 1\", Ridge(solver=\"svd\")),\n",
    "    (\"Ridge - 2 \", Ridge(solver=\"lsqr\")),\n",
    "    (\"Ridge - 3\", Ridge(alpha=1.5, solver=\"svd\")),\n",
    "    (\"Ridge - 4\", Ridge(alpha=1.5, solver=\"lsqr\")),\n",
    "    (\"Ridge - 5\", Ridge(alpha=2, solver=\"svd\")),\n",
    "    (\"Ridge - 6\", Ridge(alpha=2, solver=\"lsqr\")),\n",
    "    (\"Ridge - 7\", Ridge(alpha=2.5, solver=\"svd\")),\n",
    "    (\"Ridge - 8\", Ridge(alpha=2.5, solver=\"lsqr\")),\n",
    "    (\"Lasso - 1\", Lasso(warm_start=True)),\n",
    "    (\"Lasso - 2\", Lasso(warm_start=False)),\n",
    "    (\"Lasso - 3\", Lasso(alpha=1.5, warm_start=True)),\n",
    "    (\"Lasso - 4\", Lasso(alpha=1.5, warm_start=False)),\n",
    "    (\"Lasso - 5\", Lasso(alpha=2, warm_start=True)),\n",
    "    (\"Lasso - 6\", Lasso(alpha=2, warm_start=False)),\n",
    "    (\"BayesianRidge\", BayesianRidge()),\n",
    "    (\"Kernel Ridge\", KernelRidge()),\n",
    "    (\"SVR - 1\", SVR(degree=3)),\n",
    "    (\"SVR - 2\", SVR(degree=4)),\n",
    "    (\"SVR - 3\", SVR(degree=5)),\n",
    "    (\"SVR - 4\", SVR(degree=10)),\n",
    "    (\"SVR - 5\", SVR(degree=15)),\n",
    "    (\"SVR - 6\", SVR(kernel=\"poly\",degree=3)),\n",
    "    (\"SVR - 7\", SVR(kernel=\"poly\",degree=4)),\n",
    "    (\"SVR - 8\", SVR(kernel=\"poly\",degree=5)),\n",
    "    (\"SVR - 9\", SVR(kernel=\"poly\",degree=10)),\n",
    "    (\"SVR - 10\", SVR(kernel=\"poly\",degree=15)),\n",
    "    (\"SVR - 11\", SVR(kernel=\"sigmoid\",degree=3)),\n",
    "    (\"SVR - 12\", SVR(kernel=\"sigmoid\",degree=4)),\n",
    "    (\"SVR - 13\", SVR(kernel=\"sigmoid\",degree=5)),\n",
    "    (\"SVR - 14\", SVR(kernel=\"sigmoid\",degree=10)),\n",
    "    (\"SVR - 15\", SVR(kernel=\"sigmoid\",degree=15)),\n",
    "    (\"KNN - 1\", KNeighborsRegressor(n_neighbors=5)),\n",
    "    (\"KNN - 2\", KNeighborsRegressor(n_neighbors=10)),\n",
    "    (\"KNN - 3\", KNeighborsRegressor(n_neighbors=15)),\n",
    "    (\"KNN - 4\", KNeighborsRegressor(n_neighbors=20)),\n",
    "    (\"KNN - 5\", KNeighborsRegressor(n_neighbors=25)),\n",
    "    (\"KNN - 6\", KNeighborsRegressor(n_neighbors=30)),\n",
    "    (\"KNN - 7\", KNeighborsRegressor(n_neighbors=35)),\n",
    "    (\"DT - 1\", DecisionTreeRegressor(max_depth = None)),\n",
    "    (\"DT - 2\", DecisionTreeRegressor(max_depth = 5)),\n",
    "    (\"DT - 3\", DecisionTreeRegressor(max_depth = 10)),\n",
    "    (\"DT - 4\", DecisionTreeRegressor(max_depth = 15)),\n",
    "    (\"DT - 5\", DecisionTreeRegressor(max_depth = 20)),\n",
    "    (\"DT - 6\", DecisionTreeRegressor(max_depth = 25)),\n",
    "    (\"DT - 7\", DecisionTreeRegressor(max_depth = 30)),\n",
    "    (\"RF - 1\", RandomForestRegressor(max_depth = None)),\n",
    "    (\"RF - 2\", RandomForestRegressor(max_depth = 5)),\n",
    "    (\"RF - 3\", RandomForestRegressor(max_depth = 10)),\n",
    "    (\"RF - 4\", RandomForestRegressor(max_depth = 15)),\n",
    "    (\"RF - 5\", RandomForestRegressor(max_depth = 20)),\n",
    "    (\"RF - 6\", RandomForestRegressor(max_depth = 25)),\n",
    "    (\"RF - 7\", RandomForestRegressor(max_depth = 30)),\n",
    "    (\"A - RF - 1\", RandomForestRegressor(n_estimators=150, max_depth = None)),\n",
    "    (\"A - RF - 2\", RandomForestRegressor(n_estimators=150, max_depth = 5)),\n",
    "    (\"A - RF - 3\", RandomForestRegressor(n_estimators=150, max_depth = 10)),\n",
    "    (\"A - RF - 4\", RandomForestRegressor(n_estimators=150, max_depth = 15)),\n",
    "    (\"A - RF - 5\", RandomForestRegressor(n_estimators=150, max_depth = 20)),\n",
    "    (\"A - RF - 6\", RandomForestRegressor(n_estimators=150, max_depth = 25)),\n",
    "    (\"A - RF - 7\", RandomForestRegressor(n_estimators=150, max_depth = 30)),\n",
    "    (\"B - RF - 1\", RandomForestRegressor(n_estimators=50, max_depth = None)),\n",
    "    (\"B - RF - 2\", RandomForestRegressor(n_estimators=50, max_depth = 5)),\n",
    "    (\"B - RF - 3\", RandomForestRegressor(n_estimators=50, max_depth = 10)),\n",
    "    (\"B - RF - 4\", RandomForestRegressor(n_estimators=50, max_depth = 15)),\n",
    "    (\"B - RF - 5\", RandomForestRegressor(n_estimators=50, max_depth = 20)),\n",
    "    (\"B - RF - 6\", RandomForestRegressor(n_estimators=50, max_depth = 25)),\n",
    "    (\"B - RF - 7\", RandomForestRegressor(n_estimators=50, max_depth = 30)),\n",
    "]\n",
    "\n",
    "actual_results = []\n",
    "\n",
    "well_id = X_train[\"Well ID\"]\n",
    "actual_X = X_train.drop([\"Well ID\"], axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.9)\n",
    "\n",
    "scaled_X = scaler.fit_transform(actual_X)\n",
    "pca_X = pca.fit_transform(scaled_X)\n",
    "\n",
    "for name, m in models: \n",
    "    result = training_loop(m, pca_X, Y_train, 10)\n",
    "    actual_results.append([name, result])\n",
    "    print(\"Finished model: %s, RMSE: %.2f\" % (name, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "results_df[\"Well ID\"] = test_df[\"Well ID\"]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    random_sample = train_df.sample(n=train_df.shape[0], replace=True, random_state=569214)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=0.9)\n",
    "\n",
    "    cur_y = random_sample[[\"Avg Pump Difference\"]]\n",
    "    data = random_sample.drop([\"Avg Pump Difference\", \"Well ID\"], axis = 1)\n",
    "\n",
    "    cur_model = RandomForestRegressor(n_estimators=150, max_depth = 30)\n",
    "\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "    result = training_loop(cur_model, pca_data, cur_y, 10)\n",
    "\n",
    "    well_id = test_df[[\"Well ID\"]]\n",
    "    test_data = test_df.drop([\"Well ID\", \"Avg Pump Difference\"], axis = 1)\n",
    "\n",
    "    scaled_test = scaler.transform(test_data)\n",
    "    pca_test = pca.transform(scaled_test)\n",
    "\n",
    "    raw_pred = cur_model.predict(pca_test)\n",
    "\n",
    "    results_df[\"R%d, GPM\" % (i+1)] = raw_pred\n",
    "\n",
    "    print(\"Completed\", i)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = results_df.iloc[:,1:]\n",
    "results_df[\"Est Pump Difference, GPM\"] = temp_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"Well ID\", \"Est Pump Difference, GPM\"] + results_df.columns.tolist()[1:-2]\n",
    "\n",
    "results_df = results_df[cols]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"temp_solution.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
