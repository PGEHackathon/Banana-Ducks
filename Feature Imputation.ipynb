{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f70be6a",
   "metadata": {},
   "source": [
    "# Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef8868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate MAPE\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    ape = 100 * np.abs((y_true - y_pred) / y_true)\n",
    "    return np.mean(ape)\n",
    "\n",
    "# Load your data\n",
    "data_dir = 'Train_HackathonData2024.csv'\n",
    "data = pd.read_csv(data_dir)\n",
    "\n",
    "# Define the target and feature variables\n",
    "target = 'PARENT_IN_ZONE_MIN_HYPOT'\n",
    "feature_1 = 'Area'  # Categorical\n",
    "feature_2 = 'Development Strategy'  # Categorical\n",
    "feature_3 = 'PARENT_CODEV_1050_WELL_COUNT'  # Numerical\n",
    "feature_4 = 'PARENT_3000_AVG_HYPOT_DIST'  # Numerical\n",
    "\n",
    "# Keep only the relevant features and target\n",
    "data = data[[target, feature_1, feature_2, feature_3, feature_4]]\n",
    "data = data.dropna(subset=[target])\n",
    "\n",
    "# Preprocessing\n",
    "categorical_features = [feature_1, feature_2]\n",
    "numerical_features = [feature_3, feature_4]\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters for each model\n",
    "param_grid = {\n",
    "    'Random Forest': {'model__n_estimators': [10, 50, 100], 'model__max_depth': [None, 10, 20, 30]},\n",
    "    'XGBoost': {'model__n_estimators': [50, 100, 200], 'model__learning_rate': [0.01, 0.1, 0.2]},\n",
    "    'SVR': {'model__C': [0.1, 1, 10], 'model__gamma': ['scale', 'auto']},\n",
    "    'KNN': {'model__n_neighbors': [3, 5, 7]},\n",
    "    'MLP': {'model__hidden_layer_sizes': [(50,), (100,), (50, 50)], 'model__alpha': [0.0001, 0.001, 0.01]}\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = [\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "    ('XGBoost', XGBRegressor(random_state=42)),\n",
    "    ('SVR', SVR()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('MLP', MLPRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "# K-Fold cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Dictionary to store the average MAPE for each model\n",
    "average_mape_scores = {}\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models:\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid[model_name], cv=kf, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict and calculate MAPE\n",
    "    predictions = best_model.predict(X_test)\n",
    "    mape = calculate_mape(y_test, predictions)\n",
    "    average_mape_scores[model_name] = mape\n",
    "\n",
    "# Plotting the average MAPE for each model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(average_mape_scores.keys(), average_mape_scores.values(), color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average MAPE (%)')\n",
    "plt.title('Comparison of Average MAPE Across Models with Hyperparameter Tuning')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Retrain the XGBoost model on the entire dataset (excluding missing target values)\n",
    "xgboost_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                   ('model', XGBRegressor(random_state=42))])\n",
    "grid_search_xgb = GridSearchCV(xgboost_pipeline, param_grid['XGBoost'], cv=kf, scoring='neg_mean_absolute_error')\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Load the original dataset to predict and fill in missing target values\n",
    "full_data = pd.read_csv(data_dir)\n",
    "\n",
    "# Identify the rows where the target is missing\n",
    "missing_target_indices = full_data[full_data[target].isna()].index\n",
    "\n",
    "# Predict the missing target values\n",
    "if not missing_target_indices.empty:\n",
    "    X_missing = full_data.loc[missing_target_indices, [feature_1, feature_2, feature_3, feature_4]]\n",
    "    predicted_values = grid_search_xgb.best_estimator_.predict(X_missing)\n",
    "    full_data.loc[missing_target_indices, target] = predicted_values\n",
    "\n",
    "# Save the dataset with imputed values\n",
    "full_data.to_csv('Cleaned_Train_HackathonData2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7a8d0",
   "metadata": {},
   "source": [
    "# Prediction Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a4ee83",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['num__PARENT_OUT_ZONE_MIN_HYPOT', 'num__PARENT_OUT_ZONE_MIN_MAP_DIST',\\n       'num__PARENT_1050_MEDIAN_WELL_AGE', 'num__PARENT_1050_WELL_COUNT',\\n       'num__PARENT_3000_AVG_HYPOT_DIST', 'num__PARENT_3000_AVG_MAP_DIST',\\n       'num__PARENT_3000_WELL_COUNT', 'num__CODEV_IN_ZONE_MIN_MAP_DIST',\\n       'num__CODEV_3000_AVG_HYPOT_DIST'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39268\\199714089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Preprocess the entire dataset for imputation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_for_imputation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_for_imputation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX_for_imputation_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_for_imputation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5856\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['num__PARENT_OUT_ZONE_MIN_HYPOT', 'num__PARENT_OUT_ZONE_MIN_MAP_DIST',\\n       'num__PARENT_1050_MEDIAN_WELL_AGE', 'num__PARENT_1050_WELL_COUNT',\\n       'num__PARENT_3000_AVG_HYPOT_DIST', 'num__PARENT_3000_AVG_MAP_DIST',\\n       'num__PARENT_3000_WELL_COUNT', 'num__CODEV_IN_ZONE_MIN_MAP_DIST',\\n       'num__CODEV_3000_AVG_HYPOT_DIST'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Load the original dataset again for imputation\n",
    "data_for_imputation = pd.read_csv('Train_HackathonData2024.csv')\n",
    "\n",
    "# Preprocess the entire dataset for imputation\n",
    "X_for_imputation = data_for_imputation[features]\n",
    "X_for_imputation_transformed = preprocessing_pipeline.fit_transform(X_for_imputation)\n",
    "\n",
    "# Identify rows where target value is missing\n",
    "missing_target_mask = data_for_imputation[target].isnull()\n",
    "\n",
    "# Predict missing values using the best model\n",
    "# Note: Ensure that the best_model is the RFECV fitted model from the previous steps\n",
    "imputed_values = best_model.predict(X_for_imputation_transformed[missing_target_mask])\n",
    "\n",
    "# Impute the missing values in the dataset\n",
    "data_for_imputation.loc[missing_target_mask, target] = imputed_values\n",
    "\n",
    "# Save the cleaned dataset\n",
    "data_for_imputation.to_csv('Cleaned_Train_HackathonData2024.csv', index=False)\n",
    "\n",
    "print(\"Missing values for 'PARENT_IN_ZONE_MIN_HYPOT' have been imputed and saved to 'Cleaned_Train_HackathonData2024.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eee8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
